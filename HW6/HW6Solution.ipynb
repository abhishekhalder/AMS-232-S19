{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1. [20 points] Transients of the Value Iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For $0<\\beta<1$, consider the **finite state infinite horizon discounted MDP** in discrete time, given by\n",
    "\n",
    "$$\\begin{align*}\n",
    "&\\underset{\\gamma\\in\\Gamma}{\\text{inf}}\\quad\\mathbb{E}\\left[\\sum_{t=0}^{\\infty}\\beta^{t}\\:c\\left(x_{t},u_{t}\\right)\\right]\\\\\n",
    "& x \\sim \\text{Markov}\\left(P(u)\\right), \\quad [P_{ij}(u)]:= \\mathbb{P}\\left(x_{t+1} = j \\mid x_{t} = i, u_{t} = u\\right), \\quad i,j=1,...,n, \\quad u\\in\\mathcal{U}.\n",
    "\\end{align*}$$\n",
    "\n",
    "Let $\\mathcal{F}$ be the class of all functions $z:\\{1,...,n\\} \\mapsto \\mathbb{R}$, and define the **nonlinear** Bellman operator $T : \\mathcal{F} \\mapsto \\mathcal{F}$ as\n",
    "\n",
    "$$(Tz)(i):=\\underset{u\\in\\mathcal{U}}{\\text{inf}}\\quad\\bigg\\{c(i,u) + \\beta \\sum_{j=1}^{n}P_{ij}(u)z(j)\\bigg\\}, \\quad i=1,...,n.$$\n",
    "\n",
    "Let $h_{0}(i) := 0$ for $i=1,...,n$, and consider the $k$-th transient of the value iteration: $h_{k}=T^{k}h_{0}$. Here, $T^{k}$ denotes the $k$-fold composition of the Bellman operator, i.e., $T^{k}\\equiv\\underbrace{T \\circ T \\circ ... \\circ T}_{k\\;\\text{times}}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (a) [15 points] Transient value function iterate and the finite horizon OCP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let the value function associated with the **$k$-stage finite horizon OCP** be\n",
    "\n",
    "$$\\begin{align*}W_{k}(i) \\: := \\: \n",
    "&\\underset{\\gamma\\in\\Gamma}{\\text{inf}}\\quad\\mathbb{E}\\left[\\sum_{t=0}^{k-1}\\beta^{t}\\:c\\left(x_{t},u_{t}\\right) \\:\\bigg\\vert\\: x_{0}=i\\right]\\\\\n",
    "& x \\sim \\text{Markov}\\left(P(u)\\right), \\quad [P_{ij}(u)]:= \\mathbb{P}\\left(x_{t+1} = j \\mid x_{t} = i, u_{t} = u\\right), \\quad i,j=1,...,n, \\quad u\\in\\mathcal{U}.\n",
    "\\end{align*}$$\n",
    "\n",
    "Carefully prove that $h_{k}(i)=W_{k}(i)$, $i=1,...,n$. [Hint: Induction]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution for part (a):\n",
    "For $k=1$, we have \n",
    "$$h_{1}(i):=Th_{0}(i) = \\underset{u\\in\\mathcal{U}}{\\inf} \\{c(i,u) + 0\\} = \\underset{u\\in\\mathcal{U}}{\\inf} c(i,u).$$\n",
    "On the other hand, \n",
    "$$W_{1}(i) := \\underset{\\gamma\\in\\Gamma}{\\inf}\\:\\mathbb{E}\\left[\\beta^{0}c(x_{0},u_{0}) \\mid x_{0}=i\\right] = \\underset{\\gamma\\in\\{\\gamma_{0}\\}}{\\inf}\\:c(i,u_{0}) =  \\underset{u_{0}\\in\\mathcal{U}}{\\inf}\\:c(i,u_{0}).$$\n",
    "Therefore, $h_{1}(i)=W_{1}(i)$ for all $i=1,...,n$.\n",
    "\n",
    "For some $k > 1$, let us now make the inductive hypothesis that $h_{k}(i) = W_{k}(i)$ for all $i=1,...,n$. We will now prove that $h_{k+1}(i)=W_{k+1}(i)$. For this, note that\n",
    "\n",
    "$$\\begin{align*}\n",
    "W_{k+1}(i) \\: &:= \\: \n",
    "\\underset{\\gamma\\in\\Gamma}{\\text{inf}}\\quad\\mathbb{E}\\left[\\sum_{t=0}^{k}\\beta^{t}\\:c\\left(x_{t},u_{t}\\right) \\:\\bigg\\vert\\: x_{0}=i\\right]\\\\\n",
    "&= \\underset{\\gamma\\in\\Gamma}{\\inf}\\quad\\mathbb{E}\\left[\\beta^{0}c(x_{0},u_{0})\\mid x_{0}=i\\right] \\: + \\: \\beta\\mathbb{E}\\left[c(x_1, u_1) + \\beta c(x_2, u_2) + ... + \\beta^{k-1}c(x_{k}, u_{k}) \\mid x_{0}=i\\right]\\\\\n",
    "&= \\underset{\\gamma\\in\\Gamma}{\\inf}\\quad \\bigg\\{c(i,u) + \\beta\\sum_{j=1}^{n}P_{ij}(u)\\underset{\\gamma\\in\\Gamma}{\\inf}\\mathbb{E}\\left[\\sum_{t=0}^{k-1}\\beta^{t}c(x_t, u_t) \\mid x_{0}=j\\right]\\bigg\\}\\\\\n",
    "&= \\underset{u\\in\\mathcal{U}}{\\inf}\\quad \\bigg\\{c(i,u) + \\beta\\sum_{j=1}^{n}P_{ij}(u)W_{k}(j)\\bigg\\} \\qquad\\text{(by definition)}\\\\\n",
    "&= \\underset{u\\in\\mathcal{U}}{\\inf}\\quad \\bigg\\{c(i,u) + \\beta\\sum_{j=1}^{n}P_{ij}(u)h_{k}(j)\\bigg\\} \\qquad\\text{(by inductive hypothesis)}\\\\\n",
    "&= (Th_{k})(i) =: h_{k+1}(i), \n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "which completes the inductive proof."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b) [5 points] Interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Give clear physical interpretation of the mathematical result derived in part (a)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution for part (b):\n",
    "The result derived in part (a) shows that the $k$-step transient of the value iteration associated with an infinite horizon discounted MDP, starting from the zero function, coincides with the corresponding value function of a finite $k$-horizon discounted MDP. This is surprising since the value iteration was introduced as an asymptotic algorithm to solve the infinite horizon MDP, by exploiting the contraction properties of the Bellman operator. While the initial guess $h_{0}(i)$ is irrelevant in the asymptotic sense, the transient iterates of course depend on the initial guess. But a-priori it is hard to imagine if the transient iterates would have any physical meaning. This exercise reveals that for the special initial guess of zero function, the transients of the value iterate do have a natural meaning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Problem 2. [30 points] Finite Horizon LQR Redux"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this exercise is to revisit the **finite horizon LQR in discrete time via dynamic programming**. To recap the treatment via PMP, please review Lecture 9, slides 18-22. The problem considered is as follows:\n",
    "\n",
    "$$\\begin{align*} \n",
    "&\\underset{\\{\\gamma_{t}\\}_{t=0}^{N-1}\\in\\Gamma}{\\inf}\\:\\frac{1}{2}\\bigg\\{x_{N}^{\\top}Mx_{N} + \\sum_{t=0}^{N-1}\\left(x_{t}^{\\top}Qx_{t} + u_{t}^{\\top}Ru_{t}\\right)\\bigg\\}\\\\\n",
    "& x_{t+1} = Ax_{t} + Bu_{t}, \\quad x_{0}\\;\\text{given}, \\quad x\\in\\mathbb{R}^{n}, \\quad u\\in\\mathbb{R}^{m},\n",
    "\\end{align*}$$\n",
    "\n",
    "wherein as usual $M,Q \\succeq 0$, $R \\succ 0$, and $\\Gamma$ is the set of all (time-varying) history-dependent randomized policies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (a) [(2 + 2) + 6 = 10 points] The dynamic programming equation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let the value function $V_{k}$ be defined as\n",
    "\n",
    "$$V_{k}(x) := \\underset{\\{\\gamma_{t}\\}_{t=k}^{N-1}\\in\\Gamma}{\\inf}\\:\\frac{1}{2}\\bigg\\{x_{N}^{\\top}Mx_{N} + \\sum_{t=k}^{N-1}\\left(x_{t}^{\\top}Qx_{t} + u_{t}^{\\top}Ru_{t}\\right)\\:\\bigg\\vert\\: x_{k}=x\\bigg\\}.$$\n",
    "\n",
    "(a.1) What is the physical interpretation of $V_{k}(x)$? What is the physical interpretation of $V_{0}(x_{0})$?\n",
    "\n",
    "(a.2) Write down the dynamic programming equation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b) [(10 + 5) + 5 = 20 points] Solve the dynamic programming equation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b.1) To solve the recursion derived in (a.2), start with the guess that the value function $V_{k+1}(x) = \\frac{1}{2}x^{\\top}P_{k+1} x$ for some $P_{k+1} \\succeq 0$. Then **prove that** the value function $V_{k}(x)$ has the same structural form, i.e., $V_{k}(x) = \\frac{1}{2}x^{\\top}P_{k} x$ for some matrix $P_{k}$, expressed as an **explicit function** of $P_{k+1}$. From there, **prove that** $P_{k} \\succeq 0$. \n",
    "\n",
    "(b.2) Use your answer in part (b.1) to **show that** the optimal policy is a time-varying linear state feedback. Is this conclusion same or different from what we derived via PMP in Lecture 9? **Explain**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
