{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1. [70 points] Finite Horizon OCP in Continuous-time  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the finite horizon (fixed terminal time $T$) **deterministic OCP** in continuous-time, given by\n",
    "\n",
    "$$\\begin{align*}\n",
    "&\\underset{\\gamma\\in\\Gamma}{\\text{min}}\\quad e^{-\\beta T}q x(T) \\:+\\: \\displaystyle\\int_{0}^{T}e^{-\\beta t}\\left(x + cu^{2}\\right)\\:{\\mathrm{d}}t\\\\\n",
    "& \\dot{x} = a - u\\:\\sqrt{x}, \\quad x(0)=x_{0}\\in\\mathbb{R}_{>0}, \\quad x\\in\\mathcal{X}\\equiv\\mathbb{R}_{>0}, \\quad u\\in\\mathcal{U}\\equiv\\mathbb{R}_{>0}.\n",
    "\\end{align*}$$\n",
    "\n",
    "Here, the parameters $a,\\beta,c,q>0$. Our objective is to compute the optimal state feedback control $u_{\\rm{opt}}=\\gamma_{\\rm{opt}}(t,x)$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (a) [45 points] Dynamic Programming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a.1) [10 points] **Derive the Dynamic Programming (DP) equation** (i.e., the HJB PDE) for the value function $V(t,x)$ associated with the above OCP. Your final answer should not have any minimization operator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a.2) [5 points] Clearly write down the **terminal condition** for the PDE derived in part (a.1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a.3) [15 points] To solve the HJB PDE terminal value problem in (a.1)-(a.2), we stare at the PDE for a while (!!!), and make the structural guess\n",
    "\n",
    "$$V(t,x) = e^{-\\beta t}\\left(A(t)x + B(t)\\right),$$\n",
    "\n",
    "where $A(t),B(t)$ are some to-be-determined functions of time $t$. **Derive the optimal state-feedback controller** $u_{\\rm{opt}}=\\gamma_{\\rm{opt}}(t,x)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a.4) [15 points] Use your solution in (a.3) to **write a code generating the following 3 figures**: (i) trajectory plots: $A,B$ as functions of $t$, (ii) surface plot: $u_{\\rm{opt}}$ as function of $t, x$, (iii) surface plot: $V$ as function of $t, x$. Use the following data for this purpose: $a=1, \\beta = 2, c=3, q = 5, T = 2, x=0.1:0.1:10$. For surface plots, you can use MATLAB surfc or its equivalent.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b) [25 points] PMP "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b.1) [10 points] Instead of using DP as in part (a), **use PMP to derive the state-costate ODE 2PBVP**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b.2) [5 + 5 = 10 points] **Derive the structural form of optimal control** using PMP. **Compare and comment on the same with that obtained from DP**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b.3) [5 points] **Briefly explain** why solving via DP approach in part (a) may be preferred for our OCP compared to solving the equations derived in (b.1)-(b.2)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Problem 2. [30 points] Infinite Horizon OCP in Discrete Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the **infinite horizon LQR in discrete time**:\n",
    "\n",
    "$$\\begin{align*} \n",
    "&\\underset{\\{\\gamma_{t}\\}_{t=0}^{\\infty}\\in\\Gamma}{\\inf}\\:\\sum_{t=0}^{\\infty}\\left(x_{t}^{\\top}Qx_{t} + u_{t}^{\\top}Ru_{t}\\right)\\\\\n",
    "& x_{t+1} = A_{t}x_{t} + B_{t}u_{t}, \\quad x_{0}\\;\\text{given}, \\quad x\\in\\mathbb{R}^{n}, \\quad u\\in\\mathbb{R}^{m},\n",
    "\\end{align*}$$\n",
    "\n",
    "wherein as usual $Q \\succeq 0$, $R \\succ 0$, and $\\Gamma$ is the set of all (time-varying) history-dependent randomized policies. The dynamics is a linear time-varying (LTV) system with\n",
    "\n",
    "$$A_{t} = \\begin{cases}\n",
    "A_{\\rm{e}} & \\text{if}\\quad t\\quad\\text{is even},\\\\\n",
    "A_{\\rm{o}} & \\text{if}\\quad t\\quad\\text{is odd},\n",
    "\\end{cases} \\qquad B_{t} = \\begin{cases}\n",
    "B_{\\rm{e}} & \\text{if}\\quad t\\quad\\text{is even},\\\\\n",
    "B_{\\rm{o}} & \\text{if}\\quad t\\quad\\text{is odd},\n",
    "\\end{cases}$$\n",
    "\n",
    "where $(A_{\\rm{e}},A_{\\rm{o}})$ and $(B_{\\rm{e}},B_{\\rm{o}})$ are two fixed pair of matrices of approprate dimension. In other words, this is a periodic LTV system with period 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (a) [10 + 10 = 20 points] Dynamic Programming Equation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a.1) From our knowledge of DP, the infinite horizon value function should not explicitly depend on time $t$. On the other hand, from our knowledge of LQR, it is reasonable to conjecture that the value function be quadratic, i.e., \n",
    "\n",
    "$$V_{t}(x) = \\begin{cases}\n",
    "V_{\\rm{e}}(x) = x^{\\top}P_{\\rm{e}}x & \\text{if}\\quad t\\quad\\text{is even},\\\\\n",
    "V_{\\rm{o}}(x) = x^{\\top}P_{\\rm{o}}x & \\text{if}\\quad t\\quad\\text{is odd},\n",
    "\\end{cases}$$\n",
    "\n",
    "for some to-be-determined matrices $P_{\\rm{e}},P_{\\rm{o}} \\succeq 0$. You DO NOT need to verify this conjecture. Instead, use this guess together with the DP equation, to derive **two coupled matrix algebraic equations** for $P_{\\rm{e}}$ and $P_{\\rm{o}}$. \n",
    "\n",
    "(a.2) **Rewrite** the two coupled matrix equations in part (a.1) as a single discrete-time algebraic Riccati equation (DARE), of the familiar form:\n",
    "\n",
    "$$P_{\\infty} = \\widehat{Q} + A^{\\top}P_{\\infty}A - A^{\\top}P_{\\infty}B\\left(\\widehat{R} + B^{\\top}P_{\\infty}B\\right)^{-1}B^{\\top}P_{\\infty}A,$$\n",
    "    \n",
    "for some appropriately defined matrices $A,B,\\widehat{Q},\\widehat{R},P_{\\infty}$. In other words, write $A,B,\\widehat{Q},\\widehat{R},P_{\\infty}$ in terms of the data of the original problem: $A_{\\rm{e}}, A_{\\rm{o}}, B_{\\rm{e}}, B_{\\rm{o}}, Q, R, P_{\\rm{e}},P_{\\rm{o}}$.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b) [5 + 5 = 10 points] Optimal Control "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b.1) Use the conclusion of (a.2) to **argue that** the infinite horizon optimal controller for our period 2 LTV system must be of the form:\n",
    "\n",
    "$$u(t,x) = \\begin{cases}\n",
    "K_{\\rm{e}}x & \\text{if}\\quad t\\quad\\text{is even},\\\\\n",
    "K_{\\rm{o}}x & \\text{if}\\quad t\\quad\\text{is odd},\n",
    "\\end{cases}$$\n",
    "\n",
    "for a pair of constant matrices $K_{\\rm{e}}, K_{\\rm{o}}$ of appropriate dimension. (You can assume that the DARE in (a.2) has unique positive semi-definite solution.)\n",
    "\n",
    "(b.2) **Determine** the feedback gain matrices $K_{\\rm{e}}, K_{\\rm{o}}$ in part (b.1) as explicit functions of the data of the original problem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
