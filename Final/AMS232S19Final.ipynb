{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1. [70 points] Deterministic OCP in Continuous-time  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the finite horizon (fixed terminal time $T$) **deterministic OCP** in continuous-time, given by\n",
    "\n",
    "$$\\begin{align*}\n",
    "&\\underset{\\gamma\\in\\Gamma}{\\text{min}}\\quad e^{-\\beta T}q x(T) \\:+\\: \\displaystyle\\int_{0}^{T}e^{-\\beta t}\\left(x + cu^{2}\\right)\\:{\\mathrm{d}}t\\\\\n",
    "& \\dot{x} = a - u\\:\\sqrt{x}, \\quad a,\\beta,c,q>0, \\quad x(0)=x_{0}\\in\\mathbb{R}_{>0}, \\quad x\\in\\mathbb{R}_{>0}, \\quad u\\in\\mathbb{R}_{>0}.\n",
    "\\end{align*}$$\n",
    "\n",
    "Our objective is to compute the optimal feedback control $u_{\\rm{opt}}=\\gamma_{\\rm{opt}}(t,x)$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (a) [45 points] Dynamic Programming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a.1) [10 points] **Derive the Dynamic Programming (DP) equation** (i.e., the HJB PDE) for the value function $V(t,x)$ associated with our OCP. Your final answer should not have any minimization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a.2) [5 points] Clearly write down the **terminal condition** for the PDE derived in part (a.1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a.3) [15 points] To solve the HJB PDE terminal value problem in (a.1)-(a.2), we stare at the PDE for a while (!!!), and make the structural guess\n",
    "\n",
    "$$V(t,x) = e^{-\\beta t}\\left(A(t)x + B(t)\\right),$$\n",
    "\n",
    "where $A(t),B(t)$ are some to-be-determined functions of time $t$. **Derive the optimal state-feedback controller** $u_{\\rm{opt}}=\\gamma_{\\rm{opt}}(t,x)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a.4) [15 points] Use your solution in (a.3) to **write a code generating the following 3 figures**: (i) trajectory plots: $A,B$ as functions of $t$, (ii) surface plot: $u_{\\rm{opt}}$ as function of $t, x$, (iii) surface plot: $V$ as function of $t, x$. Use the following data for this purpose: $a=1, \\beta = 2, c=3, q = 5, T = 2, x=0.1:0.1:10$. Please make sure that your plots are legible. For surface plots, you can use MATLAB surfc or its equivalent.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b) [25 points] PMP "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b.1) [10 points] Instead of using DP as in part (a), **use PMP to derive the state-costate ODE 2PBVP**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b.2) [5 + 5 = 10 points] **Derive the optimal control** using PMP. **Compare and comment on its structural form with that obtained from DP**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b.3) [5 points] **Briefly explain** why solving via DP approach in part (a) may be preferred for our OCP compared to solving the equations derived in (b.1)-(b.2)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Problem 2. [30 points] Finite Horizon LQR Redux"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this exercise is to revisit the **finite horizon LQR in discrete time via dynamic programming**. To recap the treatment via PMP, please review Lecture 9, slides 18-22. The problem considered is as follows:\n",
    "\n",
    "$$\\begin{align*} \n",
    "&\\underset{\\{\\gamma_{t}\\}_{t=0}^{N-1}\\in\\Gamma}{\\inf}\\:\\frac{1}{2}\\bigg\\{x_{N}^{\\top}Mx_{N} + \\sum_{t=0}^{N-1}\\left(x_{t}^{\\top}Qx_{t} + u_{t}^{\\top}Ru_{t}\\right)\\bigg\\}\\\\\n",
    "& x_{t+1} = Ax_{t} + Bu_{t}, \\quad x_{0}\\;\\text{given}, \\quad x\\in\\mathbb{R}^{n}, \\quad u\\in\\mathbb{R}^{m},\n",
    "\\end{align*}$$\n",
    "\n",
    "wherein as usual $M,Q \\succeq 0$, $R \\succ 0$, and $\\Gamma$ is the set of all (time-varying) history-dependent randomized policies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (a) [(2 + 2) + 6 = 10 points] The dynamic programming equation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let the value function $V_{k}$ be defined as\n",
    "\n",
    "$$V_{k}(x) := \\underset{\\{\\gamma_{t}\\}_{t=k}^{N-1}\\in\\Gamma}{\\inf}\\:\\frac{1}{2}\\bigg\\{x_{N}^{\\top}Mx_{N} + \\sum_{t=k}^{N-1}\\left(x_{t}^{\\top}Qx_{t} + u_{t}^{\\top}Ru_{t}\\right)\\:\\bigg\\vert\\: x_{k}=x\\bigg\\}.$$\n",
    "\n",
    "(a.1) What is the physical interpretation of $V_{k}(x)$? What is the physical interpretation of $V_{0}(x_{0})$?\n",
    "\n",
    "(a.2) Write down the dynamic programming equation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b) [(10 + 5) + 5 = 20 points] Solve the dynamic programming equation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b.1) To solve the recursion derived in (a.2), start with the guess that the value function $V_{k+1}(x) = \\frac{1}{2}x^{\\top}P_{k+1} x$ for some $P_{k+1} \\succeq 0$. Then **prove that** the value function $V_{k}(x)$ has the same structural form, i.e., $V_{k}(x) = \\frac{1}{2}x^{\\top}P_{k} x$ for some matrix $P_{k}$, expressed as an **explicit function** of $P_{k+1}$. From there, **prove that** $P_{k} \\succeq 0$. \n",
    "\n",
    "(b.2) Use your answer in part (b.1) to **show that** the optimal policy is a time-varying linear state feedback. Is this conclusion same or different from what we derived via PMP in Lecture 9? **Explain**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
